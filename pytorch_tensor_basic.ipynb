{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHdvzXl8hMQPObT74CIVny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6X10/advanced-statistical-data-analysis/blob/main/pytorch_tensor_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tf3MhYG4HLhj"
      },
      "outputs": [],
      "source": [
        "#세팅\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch #pytorch numpy와 유사.실제로 사용하는 attribute, function 거의 1:1 mapping 되나 이름 등이 다를 수 있음->구글링하세요 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#개발환경 확인\n",
        "print(sys.version)\n",
        "print(np.__version__)\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zktNrV8yHguz",
        "outputId": "55258920-1166-4867-e6b4-8719081d3bd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.14 (default, Sep  8 2022, 00:06:44) \n",
            "[GCC 7.5.0]\n",
            "1.21.6\n",
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#사용가능한 gpu 확인\n",
        "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
        "print(available_gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NXxv8mkHyE_",
        "outputId": "fd7589d7-eec3-4f7d-af5c-e760608f0692"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<torch.cuda.device object at 0x7fc5811db4d0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device0=torch.device(\"cuda:0\") #0번째 slot의 gpu 카드를 device0라고 명명"
      ],
      "metadata": {
        "id": "EYgAPBYiH_6u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor initialize (standard gaussian에서 2,3,4 shape을 가진 tensor 만듦)\n",
        "#numpy\n",
        "a_np = np.random.randn(2,3,4)\n",
        "#pytorch\n",
        "b=torch.randn(2,3,4)\n",
        "#둘다 2X3X4 tensor가 됨"
      ],
      "metadata": {
        "id": "1pc5hJRGIPeH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_np)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQESfXB9I2gz",
        "outputId": "57c8bb51-fd9e-4027-b644-18dce741ad5d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.09604464 -1.12115469 -0.34871721  0.21708943]\n",
            "  [ 0.76756225  0.32567432  0.22123355 -0.18875871]\n",
            "  [ 1.65137359 -2.38460932 -0.54649    -1.40944374]]\n",
            "\n",
            " [[-0.79184548 -1.45594612 -1.56864535 -0.09558155]\n",
            "  [ 0.14712749 -1.23370508 -2.69592559 -0.30668969]\n",
            "  [ 0.2841632   0.07654582 -0.3541687  -0.8542382 ]]]\n",
            "tensor([[[-1.0452, -0.3664,  0.5274,  0.5042],\n",
            "         [-0.3513,  0.9132, -0.6652,  0.0483],\n",
            "         [ 1.1589,  0.3656, -0.8145, -1.6240]],\n",
            "\n",
            "        [[-0.1911, -0.3909,  0.9556,  0.4355],\n",
            "         [-0.8347, -0.4704,  1.0164,  0.7201],\n",
            "         [ 0.0521,  0.9062,  0.8530,  1.2260]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#type 비교\n",
        "print(type(a_np))\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6M8rhkmI74g",
        "outputId": "e6112601-8ad3-4734-a64d-aa3582b18041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy로 instance화한 tensor와 pytorch로 instance화한  tensor는 서로 연산이 가능한가?\n",
        "#print(a_np+b) 연산 안됨"
      ],
      "metadata": {
        "id": "q32e3OMMJC6H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BUT numpy와 pytorch는 호환성이 좋으므로 연산이 아예 불가능한 건 아님\n",
        "#1. tensor by numpy 를 tensor by pytorch로 변환\n",
        "a=torch.tensor(a_np)\n",
        "print(a+b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "oQ0OtUfnJUbQ",
        "outputId": "bbbe9375-28ae-4259-d62f-97f2db70667b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-af941c509eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#1. tensor by numpy 를 tensor by pytorch로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. tensor by pytorch를 tensor by numpy로 converting\n",
        "b_np=b.numpy()\n",
        "print(a_np+b_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9T710hGJrBS",
        "outputId": "655c07aa-2acb-4b36-fbd2-eb2df3d8e637"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.9491594  -1.48755067  0.17865854  0.72130169]\n",
            "  [ 0.4162202   1.238831   -0.44398344 -0.14042414]\n",
            "  [ 2.81026193 -2.01898683 -1.36095773 -3.0334102 ]]\n",
            "\n",
            " [[-0.98298696 -1.84679949 -0.61305564  0.33994905]\n",
            "  [-0.68761231 -1.70410491 -1.67948985  0.41343551]\n",
            "  [ 0.33627044  0.98273282  0.49879528  0.37177618]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#why numpy로도 가능한 연산을 pytorch 사용해서 연산?\n",
        "#A. gpu를 활용한 연산 가속도 때문. "
      ],
      "metadata": {
        "id": "hFoekfzQJ6z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu card 사용량 확인\n",
        "!nvidia-smi #no running processes found -> gpu 사용량 없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVgOoSEnKGRu",
        "outputId": "edde68e0-acb0-4909-8cd2-e9b188b63f78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 22 03:05:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor를 gpu에 얹어보겠음\n",
        "b=b.to(device0)\n",
        "print(b) #device='cuda:0\"라는 gpu 카드에 얹어졌음을 의미하는 문구 추가됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLwZyTJAKP8v",
        "outputId": "e72ad279-7cb1-4db9-d67b-3cb159bbdf13"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.0452, -0.3664,  0.5274,  0.5042],\n",
            "         [-0.3513,  0.9132, -0.6652,  0.0483],\n",
            "         [ 1.1589,  0.3656, -0.8145, -1.6240]],\n",
            "\n",
            "        [[-0.1911, -0.3909,  0.9556,  0.4355],\n",
            "         [-0.8347, -0.4704,  1.0164,  0.7201],\n",
            "         [ 0.0521,  0.9062,  0.8530,  1.2260]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu card에 얹은 b와 그렇지 않은 a 연산 가능? \n",
        "print(a+b) 불가능\n",
        "\n",
        "서로 다른 gpu card에 얹은 a, b 연산 가능? 불가능\n",
        "\n",
        "=> tensor 간의 연산이 가능하려면 같은 device 상에 tensor가 존재해야함"
      ],
      "metadata": {
        "id": "2nzJZzowKvJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu device에 tensor를 얹었을 때 gpu 사용량의 변화 확안\n",
        "!nvidia-smi #시스템 명령어의 결과에서 processes를 통해서 어디에서 gpu 사용하고 있는지 확인할 수ㅇ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4qQ-GgK_50",
        "outputId": "2e6c1afc-9e1e-4464-ebeb-1a569ef6e086"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 22 03:10:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    29W /  70W |    610MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.shape) #b의 shape확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeeIOPzRLX-X",
        "outputId": "2be9c43c-bda3-4c15-93fd-2999ec27522b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.dim()) #3d tensor임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZT9on1tLkmP",
        "outputId": "49e00f4c-d899-4485-894d-857298857f82"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#standard gaussian 말고 다른 random sampling\n",
        "c = torch.zeros(5,4) #5,4 shape의 0행렬\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ITalTILq9q",
        "outputId": "1b7e460a-40a2-4e44-ef9e-9e421a1efa8e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모든 entry 1인 tensor\n",
        "d=torch.ones(5,4)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chbTvPxeQQQq",
        "outputId": "1d4f164d-17a8-4f07-c479-992ecd33fded"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#.eye = identity matrix \n",
        "e=torch.eye(3) #3*3 identity matrix 만들어줘\n",
        "print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhlyCZj5QXd_",
        "outputId": "81f2fa60-ca31-4e6b-dbf4-e0ff2ce31fa0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#특정 tensor와 같은 shape을 갖는 0으로 된 tensor 만들기\n",
        "print(b)\n",
        "f=torch.zeros_like(b)\n",
        "print(f) #심지어 gpu에 얹은 특성까지 그대로 가지고 옴"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_9mbdVnQgWU",
        "outputId": "b9b0bfcc-dc04-4dc9-c417-4238998a40d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.0452, -0.3664,  0.5274,  0.5042],\n",
            "         [-0.3513,  0.9132, -0.6652,  0.0483],\n",
            "         [ 1.1589,  0.3656, -0.8145, -1.6240]],\n",
            "\n",
            "        [[-0.1911, -0.3909,  0.9556,  0.4355],\n",
            "         [-0.8347, -0.4704,  1.0164,  0.7201],\n",
            "         [ 0.0521,  0.9062,  0.8530,  1.2260]]], device='cuda:0')\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a와 shape이 같으면서 1로 된 tensor 만들기\n",
        "print(a)\n",
        "a = a.cpu() #gpu에서 내리기\n",
        "print(a)\n",
        "g=torch.ones_like(a)\n",
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZejZbprjQ156",
        "outputId": "7409acff-6d24-4b17-f756-d31fb18bfec6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0960, -1.1212, -0.3487,  0.2171],\n",
            "         [ 0.7676,  0.3257,  0.2212, -0.1888],\n",
            "         [ 1.6514, -2.3846, -0.5465, -1.4094]],\n",
            "\n",
            "        [[-0.7918, -1.4559, -1.5686, -0.0956],\n",
            "         [ 0.1471, -1.2337, -2.6959, -0.3067],\n",
            "         [ 0.2842,  0.0765, -0.3542, -0.8542]]], dtype=torch.float64)\n",
            "tensor([[[ 0.0960, -1.1212, -0.3487,  0.2171],\n",
            "         [ 0.7676,  0.3257,  0.2212, -0.1888],\n",
            "         [ 1.6514, -2.3846, -0.5465, -1.4094]],\n",
            "\n",
            "        [[-0.7918, -1.4559, -1.5686, -0.0956],\n",
            "         [ 0.1471, -1.2337, -2.6959, -0.3067],\n",
            "         [ 0.2842,  0.0765, -0.3542, -0.8542]]], dtype=torch.float64)\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor에서 특정 row, column, entry 꺼내오고 싶음 -> 리스트 다루듯이 하면됨\n",
        "a[0] #0번째 dimension의 모든 entry 가져와라"
      ],
      "metadata": {
        "id": "-ex1dmkxRhtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[1,2,3] #마지막 value 가져와"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM7ni4puSL87",
        "outputId": "42fd8a8d-8d07-45e3-cefd-1bf27be5f11b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8542, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,2,:] #특정 dimension의 특정 entry 가져와라"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w3Tpcq8SQBM",
        "outputId": "b2b2f7dd-a6ef-4f1a-beee-898bfefedf9f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.6514, -2.3846, -0.5465, -1.4094],\n",
              "        [ 0.2842,  0.0765, -0.3542, -0.8542]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch tensor는 mutable = 값을 변경할 수 있음\n",
        "a[1,2,3] =0\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob1rEyHdSdwc",
        "outputId": "530f4583-da7c-4ce5-99b0-13b30b73cd1d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0960, -1.1212, -0.3487,  0.2171],\n",
            "         [ 0.7676,  0.3257,  0.2212, -0.1888],\n",
            "         [ 1.6514, -2.3846, -0.5465, -1.4094]],\n",
            "\n",
            "        [[-0.7918, -1.4559, -1.5686, -0.0956],\n",
            "         [ 0.1471, -1.2337, -2.6959, -0.3067],\n",
            "         [ 0.2842,  0.0765, -0.3542,  0.0000]]], dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ]
}